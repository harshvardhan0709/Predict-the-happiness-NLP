{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False):\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r'[^A-Za-z0-9\\s]',r'',txt)\n",
    "    txt = re.sub(r'\\n',r' ',txt)\n",
    "    \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    \n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## join data\n",
    "test['Is_Response'] = np.nan\n",
    "alldata = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldat = cleanData(alldata['Description'], lowercase=True, remove_stops=True, stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldat = alldat.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0', u'room', u'kind', u'clean', u'stro', u'1', u'stay', u'crown', u'plaza', u'april', u'april', u'2', u'book', u'hotel', u'hotwir', u'low', u'3', u'stay', u'husband', u'son', u'way', u'4', u'girlfriend', u'stay', u'celebr', u'5', u'room', u'one', u'nice', u'clearli', u'6', u'husband', u'stay', u'hotel', u'f', u'7', u'wife', u'stay', u'gloriou', u'citi', u'whi', u'8', u'boyfriend', u'stay', u'fairmont', u'9', u'wonder', u'staff', u'great', u'locat', u'de', u'10', u'step', u'time', u'squar', u'nice', u'room', u'stay', u'n', u'11', u'wife', u'kid', u'stay', u'valenti', u'12', u'stay', u'jolli', u'madison', u'xma', u'per', u'13', u'highli', u'recommend', u'hawthorn', u'terrac', u'14', u'found', u'hotel', u'clean', u'nice', u'locat', u'go', u'15', u'stay', u'elan', u'th', u'th', u'octob', u'16', u'pricelin', u'sent', u'us', u'hotel', u'acceptin', u'17', u'old', u'cheap', u'furnituresour', u'chair', u'simpli', u'18', u'stay', u'night', u'realli', u'ha', u'19', u'servic', u'fine', u'hotel', u'fel', u'20', u'stay', u'mani', u'hilton', u'properti', u'exp', u'21', u'everyth', u'could', u'want', u'hotel', u'22', u'much', u'want', u'stay', u'boutiqu', u'hotel', u'23', u'realli', u'like', u'hotel', u'staff', u'wond', u'24', u'wife', u'spent', u'day', u'month', u'25', u'stay', u'hotel', u'two', u'night', u'th', u'26', u'took', u'girl', u'trip', u'la', u'idea', u'27', u'stay', u'girlfriend', u'long', u'weekend', u'28', u'stay', u'numer', u'time', u'never', u'29', u'public', u'area', u'nice', u'look', u'staf', u'68306', u'palomar', u'nice', u'hotel', u'noth', u'special', u'68307', u'part', u'good', u'hotel', u'68308', u'book', u'hotel', u'pricelin', u'68309', u'pay', u'top', u'price', u'room', u'pa', u'68310', u'stay', u'march', u'san', u'antonio', u'68311', u'realli', u'conveni', u'locat', u'walk', u'68312', u'room', u'clean', u'nthe', u'staff', u'went', u'ab', u'68313', u'phone', u'live', u'area', u'work', u'fi', u'68314', u'travel', u'throughout', u'world', u'work', u'68315', u'got', u'toogoodtobetru', u'rate', u'motor', u'68316', u'got', u'back', u'morn', u'new', u'york', u'68317', u'book', u'doubl', u'hotal', u'room', u'arriv', u'late', u'68318', u'high', u'mayb', u'that', u'go', u'rat', u'68319', u'properti', u'alway', u'come', u'de', u'68320', u'husband', u'frequent', u'hotel', u'68321', u'hotel', u'great', u'locat', u'day', u'68322', u'husband', u'spend', u'labor', u'day', u'weekend', u'ny', u'68323', u'problem', u'hotel', u'room', u'68324', u'hotel', u'icon', u'welldesign', u'hotel', u'built', u'68325', u'book', u'hotel', u'tomo', u'got', u'good', u'68326', u'hotel', u'may', u'glamor', u'sf', u'68327', u'stay', u'night', u'room', u'overlook', u'68328', u'stay', u'three', u'night', u'june', u'lo', u'68329', u'spent', u'night', u'king', u'castia', u'bed', u'68330', u'book', u'flighthotel', u'packag', u'expedia', u'68331', u'stay', u'hotel', u'tower', u'confer', u'68332', u'tri', u'stay', u'within', u'marriott', u'famili', u'68333', u'stay', u'night', u'littl', u'dogver', u'68334', u'stay', u'yotel', u'weekend', u'v', u'68335', u'blake', u'comfort', u'everi', u'way', u'th', u'name', u'descript', u'length', u'68336', u'dtype', u'object']\n"
     ]
    }
   ],
   "source": [
    "print alldat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d7572262e546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clean description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m             \u001b[0;31m# arg is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d7572262e546>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clean description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstemming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-59bf43664552>\u001b[0m in \u001b[0;36mcleanData\u001b[0;34m(text, lowercase, remove_stops, stemming)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstemming\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/nltk/stem/porter.pyc\u001b[0m in \u001b[0;36mstem\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step1c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/nltk/stem/porter.pyc\u001b[0m in \u001b[0;36m_step1a\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'ies'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# IES  -> I\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0;34m'ss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# SS   -> SS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# S    ->\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         ])\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/nltk/stem/porter.pyc\u001b[0m in \u001b[0;36m_apply_rule_list\u001b[0;34m(self, word, rules)\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0;31m# Don't try any further rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# clean description\n",
    "alldata['Description'] = alldata['Description'].map(lambda x: cleanData(x, lowercase=True, remove_stops=True, stemming=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the functions - we'll create separate models for each type.\n",
    "countvec = CountVectorizer(analyzer='word', ngram_range = (1,1), min_df=150, max_features=500)\n",
    "tfidfvec = TfidfVectorizer(analyzer='word', ngram_range = (1,1), min_df = 150, max_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create features\n",
    "bagofwords = countvec.fit_transform(alldata['Description'])\n",
    "tfidfdata = tfidfvec.fit_transform(alldata['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 293)\t1\n",
      "  (0, 408)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 223)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 164)\t1\n",
      "  (0, 59)\t1\n",
      "  (0, 357)\t1\n",
      "  (0, 334)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 397)\t1\n",
      "  (0, 493)\t1\n",
      "  (0, 430)\t1\n",
      "  (0, 292)\t1\n",
      "  (0, 345)\t1\n",
      "  (0, 498)\t1\n",
      "  (0, 211)\t2\n",
      "  (0, 395)\t1\n",
      "  (0, 160)\t1\n",
      "  (0, 300)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 451)\t1\n",
      "  (0, 184)\t1\n",
      "  (0, 65)\t2\n",
      "  :\t:\n",
      "  (68335, 169)\t2\n",
      "  (68335, 359)\t1\n",
      "  (68335, 106)\t1\n",
      "  (68335, 170)\t1\n",
      "  (68335, 473)\t1\n",
      "  (68335, 202)\t1\n",
      "  (68335, 139)\t1\n",
      "  (68335, 220)\t1\n",
      "  (68335, 485)\t4\n",
      "  (68335, 380)\t1\n",
      "  (68335, 88)\t1\n",
      "  (68335, 218)\t8\n",
      "  (68335, 376)\t1\n",
      "  (68335, 302)\t1\n",
      "  (68335, 212)\t2\n",
      "  (68335, 66)\t1\n",
      "  (68335, 24)\t4\n",
      "  (68335, 1)\t1\n",
      "  (68335, 19)\t5\n",
      "  (68335, 160)\t2\n",
      "  (68335, 65)\t1\n",
      "  (68335, 296)\t2\n",
      "  (68335, 462)\t1\n",
      "  (68335, 358)\t2\n",
      "  (68335, 410)\t14\n"
     ]
    }
   ],
   "source": [
    "print(bagofwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 410)\t0.13273036764\n",
      "  (0, 358)\t0.0899677660899\n",
      "  (0, 462)\t0.232881494521\n",
      "  (0, 226)\t0.270126250927\n",
      "  (0, 296)\t0.168157570626\n",
      "  (0, 82)\t0.131084455044\n",
      "  (0, 65)\t0.195467351764\n",
      "  (0, 184)\t0.110847824195\n",
      "  (0, 451)\t0.100695333724\n",
      "  (0, 33)\t0.27909545746\n",
      "  (0, 300)\t0.252471529002\n",
      "  (0, 160)\t0.0836944843052\n",
      "  (0, 395)\t0.111349231137\n",
      "  (0, 211)\t0.26920998804\n",
      "  (0, 498)\t0.113221313515\n",
      "  (0, 345)\t0.242664759339\n",
      "  (0, 292)\t0.109471222058\n",
      "  (0, 430)\t0.194996185206\n",
      "  (0, 493)\t0.125176781752\n",
      "  (0, 397)\t0.209408409069\n",
      "  (0, 7)\t0.154014760258\n",
      "  (0, 334)\t0.191154409127\n",
      "  (0, 357)\t0.186441248048\n",
      "  (0, 59)\t0.146947453494\n",
      "  (0, 164)\t0.176866809407\n",
      "  :\t:\n",
      "  (68335, 110)\t0.123318650965\n",
      "  (68335, 407)\t0.0974446802074\n",
      "  (68335, 469)\t0.0794572254308\n",
      "  (68335, 73)\t0.136618253452\n",
      "  (68335, 286)\t0.0669001684072\n",
      "  (68335, 347)\t0.0846144283958\n",
      "  (68335, 179)\t0.0656976381432\n",
      "  (68335, 427)\t0.0954558217411\n",
      "  (68335, 389)\t0.101958611271\n",
      "  (68335, 399)\t0.092922907913\n",
      "  (68335, 431)\t0.109671314344\n",
      "  (68335, 55)\t0.13515680916\n",
      "  (68335, 189)\t0.120034614427\n",
      "  (68335, 245)\t0.107793196582\n",
      "  (68335, 421)\t0.129550908402\n",
      "  (68335, 92)\t0.117752074429\n",
      "  (68335, 222)\t0.128027381347\n",
      "  (68335, 27)\t0.108364127147\n",
      "  (68335, 295)\t0.115833428351\n",
      "  (68335, 340)\t0.128500021357\n",
      "  (68335, 342)\t0.211568758181\n",
      "  (68335, 351)\t0.138525345891\n",
      "  (68335, 53)\t0.122312673016\n",
      "  (68335, 34)\t0.095997960081\n",
      "  (68335, 186)\t0.129634838246\n"
     ]
    }
   ],
   "source": [
    "print(tfidfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label encode categorical features in data given\n",
    "cols = ['Browser_Used','Device_Used']\n",
    "\n",
    "for x in cols:\n",
    "    lbl = LabelEncoder()\n",
    "    alldata[x] = lbl.fit_transform(alldata[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataframe for features\n",
    "bow_df = pd.DataFrame(bagofwords.todense())\n",
    "tfidf_df = pd.DataFrame(tfidfdata.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set column names\n",
    "bow_df.columns = ['col'+ str(x) for x in bow_df.columns]\n",
    "tfidf_df.columns = ['col' + str(x) for x in tfidf_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create separate data frame for bag of words and tf-idf\n",
    "\n",
    "bow_df_train = bow_df[:len(train)]\n",
    "bow_df_test = bow_df[len(train):]\n",
    "\n",
    "tfid_df_train = tfidf_df[:len(train)]\n",
    "tfid_df_test = tfidf_df[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the merged data file into train and test respectively\n",
    "train_feats = alldata[~pd.isnull(alldata.Is_Response)]\n",
    "test_feats = alldata[pd.isnull(alldata.Is_Response)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "### set target variable\n",
    "\n",
    "train_feats['Is_Response'] = [1 if x == 'happy' else 0 for x in train_feats['Is_Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge count (bag of word) features into train\n",
    "train_feats1 = pd.concat([train_feats[cols], bow_df_train], axis = 1)\n",
    "test_feats1 = pd.concat([test_feats[cols], bow_df_test], axis=1)\n",
    "\n",
    "test_feats1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge into a new data frame with tf-idf features\n",
    "train_feats2 = pd.concat([train_feats[cols], tfid_df_train], axis=1)\n",
    "test_feats2 = pd.concat([test_feats[cols], tfid_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's check cross validation score of the model\n",
    "# cv score acts a unbiased estimate of models accuracy on unseen data\n",
    "\n",
    "mod1 = GaussianNB()\n",
    "target = train_feats['Is_Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7548793   0.74518366  0.75160545  0.75032109  0.756486  ]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes 1\n",
    "print(cross_val_score(mod1, train_feats1, target, cv=5, scoring=make_scorer(accuracy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.78929122  0.795402    0.79244798  0.79822759  0.79874133]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes 2 - tfidf is giving higher CV score\n",
    "print(cross_val_score(mod1, train_feats2, target, cv=5, scoring=make_scorer(accuracy_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make our first set of predictions\n",
    "\n",
    "clf1 = GaussianNB()\n",
    "clf1.fit(train_feats1, target)\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(train_feats2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds1 = clf1.predict(test_feats1)\n",
    "preds2 = clf2.predict(test_feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_labels(x):\n",
    "    if x == 1:\n",
    "        return \"happy\"\n",
    "    return \"not_happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds1})\n",
    "sub1['Is_Response'] = sub1['Is_Response'].map(lambda x: to_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub2 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds2})\n",
    "sub2['Is_Response'] = sub2['Is_Response'].map(lambda x: to_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = sub1[['User_ID', 'Is_Response']]\n",
    "sub2 = sub2[['User_ID', 'Is_Response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## write submission files\n",
    "sub1.to_csv('sub1_cv.csv', index=False)\n",
    "sub2.to_csv('sub2_tf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the data in format lgb accepts\n",
    "d_train = lgb.Dataset(train_feats1, label = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set parameters\n",
    "## you can tune the parameters can try to better score\n",
    "\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'learning_rate': 0.078666, \n",
    "    'max_depth': 7, \n",
    "    'num_leaves': 21, \n",
    "    'feature_fraction': 0.5, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f11e14800b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlgb_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks)\u001b[0m\n\u001b[1;32m    440\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/lightgbm/engine.pyc\u001b[0m in \u001b[0;36mhandlerFunction\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandlerFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/harsh/.local/lib/python2.7/site-packages/lightgbm/basic.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1414\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1415\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1417\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgb_cv = lgb.cv(params, d_train, num_boost_round=500, nfold= 5, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## get nround value which hd lowest error\n",
    "nround = lgb_cv['binary_error-mean'].index(np.min(lgb_cv['binary_error-mean']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train the model\n",
    "model = lgb.train(params, d_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make predictions\n",
    "preds = model.predict(test_feats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make submission\n",
    "\n",
    "def to_labels(x):\n",
    "    if x > 0.66:  # cutoff - you can change it and see if accuracy improves or plot AUC curve. \n",
    "        return \"happy\"\n",
    "    return \"not_happy\"\n",
    "\n",
    "sub3 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds})\n",
    "sub3['Is_Response'] = sub3['Is_Response'].map(lambda x: to_labels(x))\n",
    "sub3 = sub3[['User_ID','Is_Response']]\n",
    "sub3.to_csv('sub31_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set data format\n",
    "d_train = lgb.Dataset(train_feats2, label = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same parameters as above\n",
    "params = {'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'learning_rate': 0.05, \n",
    "    'max_depth': 5, \n",
    "    'num_leaves': 11,\n",
    "    'feature_fraction': 0.3, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's binary_error: 0.214656 + 0.00431238\n",
      "[40]\tcv_agg's binary_error: 0.197652 + 0.00501838\n",
      "[60]\tcv_agg's binary_error: 0.181701 + 0.00499341\n",
      "[80]\tcv_agg's binary_error: 0.171427 + 0.00448226\n",
      "[100]\tcv_agg's binary_error: 0.162386 + 0.00604776\n",
      "[120]\tcv_agg's binary_error: 0.157325 + 0.00549851\n",
      "[140]\tcv_agg's binary_error: 0.153832 + 0.00510883\n",
      "[160]\tcv_agg's binary_error: 0.149774 + 0.00477697\n",
      "[180]\tcv_agg's binary_error: 0.147205 + 0.00480522\n",
      "[200]\tcv_agg's binary_error: 0.144328 + 0.00484425\n",
      "[220]\tcv_agg's binary_error: 0.142505 + 0.00518644\n",
      "[240]\tcv_agg's binary_error: 0.140655 + 0.00527885\n",
      "[260]\tcv_agg's binary_error: 0.139525 + 0.00515435\n",
      "[280]\tcv_agg's binary_error: 0.137907 + 0.0054511\n",
      "[300]\tcv_agg's binary_error: 0.13711 + 0.00551162\n",
      "[320]\tcv_agg's binary_error: 0.135852 + 0.00588731\n",
      "[340]\tcv_agg's binary_error: 0.135056 + 0.0058444\n",
      "[360]\tcv_agg's binary_error: 0.13372 + 0.00536832\n",
      "[380]\tcv_agg's binary_error: 0.13318 + 0.00556489\n",
      "[400]\tcv_agg's binary_error: 0.132461 + 0.00492085\n",
      "[420]\tcv_agg's binary_error: 0.131768 + 0.00454132\n",
      "[440]\tcv_agg's binary_error: 0.131023 + 0.00447343\n",
      "[460]\tcv_agg's binary_error: 0.130278 + 0.0051908\n",
      "[480]\tcv_agg's binary_error: 0.129918 + 0.00486789\n",
      "[500]\tcv_agg's binary_error: 0.129585 + 0.00441565\n"
     ]
    }
   ],
   "source": [
    "## do cross validation to find nround i.e. at this round (iteration) we can expect lowest error\n",
    "lgb_cv = lgb.cv(params, d_train, num_boost_round=500, nfold= 5, shuffle=True, stratified=True, verbose_eval=20, early_stopping_rounds=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get nround value\n",
    "nround = lgb_cv['binary_error-mean'].index(np.min(lgb_cv['binary_error-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# train model\n",
    "model = lgb.train(params, d_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "preds = model.predict(test_feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make submission\n",
    "\n",
    "def to_labels(x):\n",
    "    if x > 0.66:\n",
    "        return \"happy\"\n",
    "    return \"not_happy\"\n",
    "\n",
    "sub4 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds})\n",
    "sub4['Is_Response'] = sub4['Is_Response'].map(lambda x: to_labels(x))\n",
    "sub4 = sub4[['User_ID','Is_Response']]\n",
    "sub4.to_csv('sub4_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import library\n",
    "from catboost import CatBoostClassifier,cv, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## catboost accepts categorical columns as a list of column numbers. In this data, all columns are categorical\n",
    "cat_cols = [x for x in range(502)] ## 502 == train_feats1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set parameters\n",
    "## you can refer the parameters here: https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/#python-reference_parameters-list\n",
    "param = {\n",
    "    'use_best_model':True,\n",
    "    'loss_function':'CrossEntropy',\n",
    "    'eval_metric':'Accuracy',\n",
    "    'iterations':1000,\n",
    "    'depth':6,\n",
    "    'learning_rate':0.03,\n",
    "    'rsm':0.3,\n",
    "    'random_seed':2017,\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set parameters\n",
    "## you can refer the parameters here: https://tech.yandex.com/catboost/doc/dg/concepts/python-reference_parameters-list-docpage/#python-reference_parameters-list\n",
    "param = {\n",
    "    'use_best_model':True,\n",
    "    'loss_function':'CrossEntropy',\n",
    "    'eval_metric':'Accuracy',\n",
    "    'iterations':1000,\n",
    "    'depth':6,\n",
    "    'learning_rate':0.03,\n",
    "    'rsm':0.3,\n",
    "    'random_seed':2017,\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## for doing cross validation, set data in Pool format\n",
    "my_dt =  Pool(train_feats1, \n",
    "           label=target,\n",
    "           cat_features=cat_cols,\n",
    "           column_description=None,\n",
    "           delimiter='\\t',\n",
    "           has_header=None,\n",
    "           weight=None, \n",
    "           baseline=None,\n",
    "           feature_names=None,\n",
    "           thread_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run cv to get best iteration\n",
    "ctb_cv = cv(param, my_dt, fold_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch best round\n",
    "best_round = ctb_cv['b\\'Accuracy\\'_test_avg'].index(np.max(ctb_cv['b\\'Accuracy\\'_test_avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define the classifer model\n",
    "model = CatBoostClassifier(iterations=best_round, learning_rate=0.03,rsm = 0.3 ,depth=6, eval_metric='Accuracy', random_seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## train model\n",
    "model.fit(my_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make predictions\n",
    "preds = model.predict(test_feats1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## make submission\n",
    "sub5 = pd.DataFrame({'User_ID':test.User_ID, 'Is_Response':preds})\n",
    "sub5['Is_Response'] = ['happy' if x == 1 else 'not_happy' for x in sub5['Is_Response']]\n",
    "sub5 = sub5[['User_ID','Is_Response']]\n",
    "sub5.to_csv('submissions/sub5_cb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
